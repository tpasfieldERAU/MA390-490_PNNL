
@article{mcgregor_large_2022,
	title = {Large batch metrology on internal features of additively manufactured parts using {X}-ray computed tomography},
	volume = {306},
	issn = {0924-0136},
	url = {https://www.sciencedirect.com/science/article/pii/S0924013622001170},
	doi = {10.1016/j.jmatprotec.2022.117605},
	abstract = {Additive manufacturing (AM) can produce complex geometries, resulting in features that can be hidden or obscured, and the measurement of these features is important for many applications. X-ray computed tomography (CT) is the only non-destructive inspection technique capable of measuring internal features that are inaccessible to optical or tactile measurements; however, batch processing of CT data can be challenging and time consuming. There is a need to develop efficient CT measurement strategies to better understand how the accuracy of internal geometries varies across different parts, processes, and materials. This study presents an automated method for batch CT metrology using open-source software, and investigates 48 nozzle parts made using 11 polymer materials and 3 AM processes. The nozzles have features critical to performance, including internal channels whose measurement would otherwise require destructive evaluation. The parts are measured using CT and the data is automatically processed, resulting in over 1000 measurements per part. The deformations that occur during manufacturing result in highly nonuniform variability within the parts, and features have significantly different accuracies depending on whether the features are located on the interior or exterior of the part. Part-to-part variability is low within a batch of parts made from a single material, generally within 35 µm. However, part variability changes significantly between materials, even when the parts are made using the same process. The research demonstrates measurement results and insights enabled by large batch CT metrology of AM parts with internal features, as well as the need to monitor part-to-part variability.},
	urldate = {2024-01-19},
	journal = {Journal of Materials Processing Technology},
	author = {McGregor, Davis J. and Bimrose, Miles V. and Tawfick, Sameh and King, William P.},
	month = aug,
	year = {2022},
	keywords = {Additive manufacturing, Metrology, Open-source software, X-ray computed tomography},
	pages = {117605},
	file = {McGregor et al. - 2022 - Large batch metrology on internal features of addi.pdf:C\:\\Users\\TJ\\Zotero\\storage\\TX36C6K2\\McGregor et al. - 2022 - Large batch metrology on internal features of addi.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\TJ\\Zotero\\storage\\5Q34LJUQ\\S0924013622001170.html:text/html},
}

@article{farago_tofu_2022,
	title = {Tofu: a fast, versatile and user-friendly image processing toolkit for computed tomography},
	volume = {29},
	issn = {1600-5775},
	shorttitle = {Tofu},
	url = {https://journals.iucr.org/s/issues/2022/03/00/tv5034/},
	doi = {10.1107/S160057752200282X},
	abstract = {Tofu is a toolkit for processing large amounts of images and for tomographic reconstruction. Complex image processing tasks are organized as workflows of individual processing steps. The toolkit is able to reconstruct parallel and cone beam as well as tomographic and laminographic geometries. Many pre- and post-processing algorithms needed for high-quality 3D reconstruction are available, e.g. phase retrieval, ring removal and de-noising. Tofu is optimized for stand-alone GPU workstations on which it achieves reconstruction speed comparable with costly CPU clusters. It automatically utilizes all GPUs in the system and generates 3D reconstruction code with minimal number of instructions given the input geometry (parallel/cone beam, tomography/laminography), hence yielding optimal run-time performance. In order to improve accessibility for researchers with no previous knowledge of programming, tofu contains graphical user interfaces for both optimization of 3D reconstruction parameters and batch processing of data with pre-configured workflows for typical computed tomography reconstruction. The toolkit is open source and extensive documentation is available for both end-users and developers. Thanks to the mentioned features, tofu is suitable for both expert users with specialized image processing needs (e.g. when dealing with data from custom-built computed tomography scanners) and for application-specific end-users who just need to reconstruct their data on off-the-shelf hardware.},
	language = {en},
	number = {3},
	urldate = {2024-01-19},
	journal = {Journal of Synchrotron Radiation},
	author = {Faragó, T. and Gasilov, S. and Emslie, I. and Zuber, M. and Helfen, L. and Vogelgesang, M. and Baumbach, T.},
	month = may,
	year = {2022},
	note = {Publisher: International Union of Crystallography},
	pages = {916--927},
	file = {Full Text PDF:C\:\\Users\\TJ\\Zotero\\storage\\KVN9WGDF\\Faragó et al. - 2022 - Tofu a fast, versatile and user-friendly image pr.pdf:application/pdf},
}

@article{du_plessis_dimensional_2021,
	title = {Dimensional metrology of additively manufactured lattice structures by combined tactile probe and {X}-ray tomography},
	volume = {3},
	copyright = {© 2021 John Wiley \& Sons, Ltd.},
	issn = {2577-6576},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mdp2.216},
	doi = {10.1002/mdp2.216},
	abstract = {Additive manufacturing allows high complexity of manufactured structures, permitting entirely new design capabilities. In the context of complex design, lattice structures hold the most promise for high complexity, tailorable and ultra-lightweight structures. These unique structures are suitable for various applications including light-weighting, energy absorption, vibration isolation, thermal management amongst many others. This new complexity leads to new manufacturing quality control and metrology challenges. Traditional metrology tools cannot access the entire structure, and the only reliable method to inspect the inner details of these structures is by X-ray computed tomography (CT). This work highlights the challenges of this process, demonstrating a novel workflow for dimensional metrology of coupon lattice samples—using a combination of surface and internal metrology using tactile probe and CT. This dual combined approach uses traditional surface coordinate measurement on exterior accessible surfaces, which is followed by internal lattice measurements. The results show a clear method and workflow for combining these technologies for a holistic dimensional inspection. The confidence gained by inspection of such lattice coupons will support the application of these lattices in end-use parts.},
	language = {en},
	number = {6},
	urldate = {2024-01-19},
	journal = {Material Design \& Processing Communications},
	author = {du Plessis, Anton and Schwaderer, Gerd and Cristofolini, Ilaria and Zago, Marco and Benedetti, Matteo},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/mdp2.216},
	keywords = {calibration, laser powder bed fusion, lattice structures, metal additive manufacturing, metrology, X-ray tomography},
	pages = {e216},
	file = {Full Text PDF:C\:\\Users\\TJ\\Zotero\\storage\\BWHZGS6M\\du Plessis et al. - 2021 - Dimensional metrology of additively manufactured l.pdf:application/pdf;Snapshot:C\:\\Users\\TJ\\Zotero\\storage\\XUIZML4J\\mdp2.html:text/html},
}

@article{ametova_computationally_2018,
	title = {A computationally inexpensive model for estimating dimensional measurement uncertainty due to x-ray computed tomography instrument misalignments},
	volume = {29},
	issn = {0957-0233},
	url = {https://dx.doi.org/10.1088/1361-6501/aab1a1},
	doi = {10.1088/1361-6501/aab1a1},
	abstract = {The recent emergence of advanced manufacturing techniques such as additive manufacturing and an increased demand on the integrity of components have motivated research on the application of x-ray computed tomography (CT) for dimensional quality control. While CT has shown significant empirical potential for this purpose, there is a need for metrological research to accelerate the acceptance of CT as a measuring instrument. The accuracy in CT-based measurements is vulnerable to the instrument geometrical configuration during data acquisition, namely the relative position and orientation of x-ray source, rotation stage, and detector. Consistency between the actual instrument geometry and the corresponding parameters used in the reconstruction algorithm is critical. Currently available procedures provide users with only estimates of geometrical parameters. Quantification and propagation of uncertainty in the measured geometrical parameters must be considered to provide a complete uncertainty analysis and to establish confidence intervals for CT dimensional measurements. In this paper, we propose a computationally inexpensive model to approximate the influence of errors in CT geometrical parameters on dimensional measurement results. We use surface points extracted from a computer-aided design (CAD) model to model discrepancies in the radiographic image coordinates assigned to the projected edges between an aligned system and a system with misalignments. The efficacy of the proposed method was confirmed on simulated and experimental data in the presence of various geometrical uncertainty contributors.},
	language = {en},
	number = {6},
	urldate = {2024-01-19},
	journal = {Measurement Science and Technology},
	author = {Ametova, Evelina and Ferrucci, Massimiliano and Chilingaryan, Suren and Dewulf, Wim},
	month = apr,
	year = {2018},
	note = {Publisher: IOP Publishing},
	pages = {065007},
	file = {IOP Full Text PDF:C\:\\Users\\TJ\\Zotero\\storage\\VPVRUHXB\\Ametova et al. - 2018 - A computationally inexpensive model for estimating.pdf:application/pdf},
}

@article{busch_application_2022,
	title = {Application of an edge detection algorithm for surface determination in industrial {X}-ray computed tomography},
	volume = {16},
	issn = {1863-7353},
	url = {https://doi.org/10.1007/s11740-021-01100-z},
	doi = {10.1007/s11740-021-01100-z},
	abstract = {Surface determination is an essential step of the measurement process in industrial X-ray computed tomography (XCT). The starting point of the surface determination process step is a single grey value threshold within a voxel volume in conventional surface determination methods. However, this value is not always found in the reconstructed volume in the local environment of the surface of the measurement object due to various artefacts, so that none or incorrect surfaces are determined. In order to find surfaces independently of a single grey value, a three-dimensional approach of the initial contour determination based on a Prewitt edge detection algorithm is presented in this work. This method is applied to different test specimens and specimen compositions which, due to their material or material constellation, their geometric properties with regard to surfaces and interfaces as well as their calibrated size and length dimensions, embody relevant properties in the examination of joining connections. It is shown that by using the surface determination method in the measurement process, both a higher metrological structure resolution and interface structure resolution can be achieved. Surface artefacts can be reduced by the application and it is also an approach to improved surface finding for the multi-material components that are challenging for XCT.},
	language = {en},
	number = {2},
	urldate = {2024-01-19},
	journal = {Production Engineering},
	author = {Busch, Matthias and Hausotte, Tino},
	month = apr,
	year = {2022},
	keywords = {Metrology, Computed tomography, Edge detection, Filter application, Pre-processing, Surface determination},
	pages = {411--422},
	file = {Full Text PDF:C\:\\Users\\TJ\\Zotero\\storage\\GU25F4HU\\Busch and Hausotte - 2022 - Application of an edge detection algorithm for sur.pdf:application/pdf},
}

@article{buratti_determination_2018,
	title = {Determination of the optimal imaging parameters in industrial computed tomography for dimensional measurements on monomaterial workpieces},
	volume = {29},
	issn = {0957-0233},
	url = {https://dx.doi.org/10.1088/1361-6501/aae4d6},
	doi = {10.1088/1361-6501/aae4d6},
	abstract = {Industrial computed tomography (CT) plays a key role in 3D coordinate metrology as an alternative to conventional coordinate measuring machines. CT measurement uncertainty depends on the setup parameters with which CT scans are performed. Currently, there is no established model that can describe the relationship between CT setup parameters and measurement uncertainty, and thus determine the optimal settings for a given measurement task. In practice, CT users choose setup parameters intuitively causing high variability in the measurement results. In this study, we enhance and validate an analytical method for optimizing imaging parameters. The proposed method is based on the assumption that minimizing the contribution of imaging parameters to measurement uncertainty corresponds to (1) maximizing image contrast and signal, (2) minimizing geometric blurring, and (3) minimizing image noise and CT artifacts. It also requires information about the workpiece nominal geometry and material composition. The proposed method calculates the optimal photon energy for precise surface determination, given the workpiece position and orientation. Tube voltage and prefilter are determined so that the resulting x-ray spectrum has an effective energy equal to the optimal energy and beam hardening artifacts are minimized. Tube current is chosen to maximize image signal, while avoiding blurring and excessive generated tube power. Exposure time is chosen as the shortest time that fully exploits the detector dynamics. The proposed method was validated by analyzing the standard deviations of CT measurements on a test phantom. An analysis of variance on the uncertainty components showed that the predicted parameters were globally optimal.},
	language = {en},
	number = {11},
	urldate = {2024-01-19},
	journal = {Measurement Science and Technology},
	author = {Buratti, A. and Grozmani, N. and Voigtmann, C. and Sartori, L. V. and Schmitt, R. H.},
	month = oct,
	year = {2018},
	note = {Publisher: IOP Publishing},
	pages = {115009},
	file = {IOP Full Text PDF:C\:\\Users\\TJ\\Zotero\\storage\\G4EX77F5\\Buratti et al. - 2018 - Determination of the optimal imaging parameters in.pdf:application/pdf},
}

@article{lifton_evaluation_2020,
	title = {Evaluation of the standard measurement uncertainty due to the {ISO50} surface determination method for dimensional computed tomography},
	volume = {61},
	issn = {0141-6359},
	url = {https://www.sciencedirect.com/science/article/pii/S014163591930159X},
	doi = {10.1016/j.precisioneng.2019.10.004},
	abstract = {Surface determination is the process by which a CT volume is converted from an image-based representation of an object to a surface-based representation. The process of surface determination relies on well-established image processing algorithms, but these algorithms are not exact, surface determination therefore contributes a component of uncertainty to X-ray CT based dimensional measurements. The purpose of this work is to develop a method for quantifying the standard uncertainty due to surface determination such that this standard uncertainty can be combined with other standard uncertainties in order to calculate the combined standard uncertainty for X-ray CT based dimensional measurements. The proposed method relies on evaluating the mode and the 68\% dispersion of the air and material grey values of a given CT data-set. These values are propagated through the ISO50 threshold calculation to give the standard uncertainty of the ISO50 threshold value from which the standard uncertainty due to the ISO50 surface determination method can be evaluated. The proposed method is verified numerically and then demonstrated experimentally for dimensional measurements of an aluminium workpiece, a polymer workpiece, and a steel additively manufactured workpiece. The results show that the measurement uncertainty due to the ISO50 surface determination method is largest for dimensions that have both internal and external surfaces such as wall thicknesses, followed by dimensions such as internal and external diameters, whilst dimensions that are not sensitive to surface determination, for example centre-to-centre distances have the smallest uncertainty due to the ISO50 surface determination method.},
	urldate = {2024-01-19},
	journal = {Precision Engineering},
	author = {Lifton, J. J. and Liu, T.},
	month = jan,
	year = {2020},
	keywords = {X-ray computed tomography, Surface determination, Dimensional metrology, Measurement uncertainty},
	pages = {82--92},
	file = {Lifton and Liu - 2020 - Evaluation of the standard measurement uncertainty.pdf:C\:\\Users\\TJ\\Zotero\\storage\\6XM5A9IM\\Lifton and Liu - 2020 - Evaluation of the standard measurement uncertainty.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\TJ\\Zotero\\storage\\MQ22JGRK\\S014163591930159X.html:text/html},
}

@article{thompson_x-ray_2016,
	title = {X-ray computed tomography for additive manufacturing: a review},
	volume = {27},
	issn = {0957-0233, 1361-6501},
	shorttitle = {X-ray computed tomography for additive manufacturing},
	url = {https://iopscience.iop.org/article/10.1088/0957-0233/27/7/072001},
	doi = {10.1088/0957-0233/27/7/072001},
	abstract = {In this review, the use of x-ray computed tomography (XCT) is examined, identifying the requirement for volumetric dimensional measurements in industrial verification of additively manufactured (AM) parts. The XCT technology and AM processes are summarised, and their historical use is documented. The use of XCT and AM as tools for medical reverse engineering is discussed, and the transition of XCT from a tool used solely for imaging to a vital metrological instrument is documented. The current states of the combined technologies are then examined in detail, separated into porosity measurements and general dimensional measurements. In the conclusions of this review, the limitation of resolution on improvement of porosity measurements and the lack of research regarding the measurement of surface texture are identified as the primary barriers to ongoing adoption of XCT in AM. The limitations of both AM and XCT regarding slow speeds and high costs, when compared to other manufacturing and measurement techniques, are also noted as general barriers to continued adoption of XCT and AM.},
	language = {en},
	number = {7},
	urldate = {2024-01-19},
	journal = {Measurement Science and Technology},
	author = {Thompson, A and Maskery, I and Leach, R K},
	month = jul,
	year = {2016},
	pages = {072001},
	file = {Thompson et al. - 2016 - X-ray computed tomography for additive manufacturi.pdf:C\:\\Users\\TJ\\Zotero\\storage\\PMCULBVH\\Thompson et al. - 2016 - X-ray computed tomography for additive manufacturi.pdf:application/pdf},
}

@article{hiller_physical_2012,
	title = {Physical characterization and performance evaluation of an x-ray micro-computed tomography system for dimensional metrology applications},
	volume = {23},
	issn = {0957-0233},
	url = {https://dx.doi.org/10.1088/0957-0233/23/8/085404},
	doi = {10.1088/0957-0233/23/8/085404},
	abstract = {This paper presents physical and metrological characterization measurements conducted for an industrial x-ray micro-computed tomography (CT) system. As is well known in CT metrology, many factors, e.g., in the scanning and reconstruction process, the image processing, and the 3D data evaluation, influence the dimensional measurement properties of the system as a whole. Therefore, it is important to know what leads to, and what are the consequences of, e.g., a geometrical misalignment of the scanner system, image unsharpness (blurring), or noise or image artefacts. In our study, the two main components of a CT scanner, i.e. the x-ray tube and the flat-panel detector, are characterized. The contrast and noise transfer property of the scanner is obtained using image-processing methods based on linear systems theory. A long-term temperature measurement in the scanner cabinet has been carried out. The dimensional measurement property has been quantified by using a calibrated ball-bar and uncertainty budgeting. Information about the performance of a CT scanner system in terms of contrast and noise transmission and sources of geometrical errors will help plan CT scans more efficiently. In particular, it will minimize the user's influence by a systematic line of action, taking into account the physical and technical limitations and influences on dimensional measurements.},
	language = {en},
	number = {8},
	urldate = {2024-01-19},
	journal = {Measurement Science and Technology},
	author = {Hiller, Jochen and Maisl, Michael and Reindl, Leonard M.},
	month = jun,
	year = {2012},
	note = {Publisher: IOP Publishing},
	pages = {085404},
}

@article{boopathiraja_near_2023,
	title = {Near {Lossless} {Compression} for {3D} {Radiological} {Images} {Using} {Optimal} {Multilinear} {Singular} {Value} {Decomposition} ({3D}-{VOI}-{OMLSVD})},
	volume = {36},
	issn = {1618-727X},
	url = {https://doi.org/10.1007/s10278-022-00687-8},
	doi = {10.1007/s10278-022-00687-8},
	abstract = {Storage and transmission of high-compression 3D radiological images that create high-quality reconstruction upon decompression are critical necessities for effective and efficient teleradiology. To cater to this need, we propose a near lossless 3D image volume compression method based on optimal multilinear singular value decomposition called “3D-VOI-OMLSVD.” The proposed strategy first eliminates any blank 2D image slices from the 3D image volume and uses the selective bounding volume (SBV) to identify and extract the volume of Interest (VOI). Following this, the VOI is decomposed with an optimal multilinear singular value decomposition (OMLSVD) to obtain the corresponding core tensor, factor matrices, and singular values that are compressed with adaptive binary range coder (ABRC), integrated as an entropy encoder. The compressed file can be transferred or transmitted and then decompressed in order to reconstruct the original image. The resultant decompressed VOI is acquired by reversing the above process and then fusing it with the background, using the bound volume coordinates associated with the compressed 3D image. The proposed method performance was tested on a variety of 3D radiological images with different imaging modalities and dimensions using quantitative evaluation metrics such as the compression rate (CR), bit rate (BR), peak signal to noise ratio (PSNR), and structural similarity index (SSIM). Furthermore, we also investigate the impact of VOI extraction on the model performance, before comparing it with two popular compression methods, namely JPEG and JPEG2000. Our proposed method, 3D-VOI-OMLSVD, displayed a high CR value, with a maximum of 37.31, and a low BR, with the lowest reported to be 0.21. The SSIM score was consistently high, with an average performance of 0.9868, while using {\textless} 1 second for decoding the image. We observe that with VOI extraction, the compression rate increases manifold, and bit rate drops significantly, and thus reduces the encoding and decoding time to a great extent. Compared to JPEG and JPEG2000, our method consistently performs better in terms of higher CR and lower BR. The results indicate that the proposed compression methodology performs consistently to create high-quality image compressions, and overall gives a better outcome when compared against two state-of-the-art and widely used methods, JPEG and JPEG2000.},
	language = {en},
	number = {1},
	urldate = {2024-01-19},
	journal = {Journal of Digital Imaging},
	author = {Boopathiraja, S. and Kalavathi, P. and Deoghare, S. and Prasath, V. B. Surya},
	month = feb,
	year = {2023},
	keywords = {Adaptive binary range coder (ABRC), Multilinear singular value decomposition (MLSVD), Near lossless compression, Selective bounding volume (SBV) method, Three-dimensional (3D) medical image, Volume of interest (VOI)},
	pages = {259--275},
	file = {Full Text PDF:C\:\\Users\\TJ\\Zotero\\storage\\YHGGZXXA\\Boopathiraja et al. - 2023 - Near Lossless Compression for 3D Radiological Imag.pdf:application/pdf},
}

@article{hosny_efficient_2020,
	title = {Efficient compression of volumetric medical images using {Legendre} moments and differential evolution},
	volume = {24},
	issn = {1433-7479},
	url = {https://doi.org/10.1007/s00500-019-03922-7},
	doi = {10.1007/s00500-019-03922-7},
	abstract = {Volumetric medical images are widely used in diagnosing and detecting health problems of patients. Large datasets of volumetric medical images required huge storage space and high network capabilities to transmit these medical images from one location to another especially in the applications of telemedicine and teleradiology. In addition, the quality of medical images plays an important role in successful diagnoses. Therefore, an efficient compression algorithm must achieve significant reduction in the size of these volumetric medical images by using high compression ratio and preserve the quality of these images for successful diagnosis. In this paper, a novel optimized compression algorithm for volumetric medical images is proposed. In this algorithm, the volumetric medical images are divided into two-dimensional (2D) slices where each slice is divided into a group of 8 × 8 nonoverlapped blocks. The Legendre moments are computed for each block where the differential evolution optimization algorithm is utilized to select the optimum moments according to minimization of the cost function. Volumetric medical images from different medical imaging modalities are used in testing and evaluating the proposed compression algorithm. The performance of the proposed algorithm is compared with the existing volumetric medical images compression algorithms where the comparison clearly shows that the proposed algorithm outperforms the existing compression algorithms in terms of mean square error, peak signal-to-noise ratio, normalized correlation coefficient, and structural similarity index.},
	language = {en},
	number = {1},
	urldate = {2024-01-19},
	journal = {Soft Computing},
	author = {Hosny, Khalid M. and Khalid, Asmaa M. and Mohamed, Ehab R.},
	month = jan,
	year = {2020},
	keywords = {Compression, Differential evolution, Legendre moments, Volumetric medical images},
	pages = {409--427},
	file = {Full Text PDF:C\:\\Users\\TJ\\Zotero\\storage\\Q7HQI4W8\\Hosny et al. - 2020 - Efficient compression of volumetric medical images.pdf:application/pdf},
}

@misc{noauthor_13517_nodate,
	title = {1.3.5.17. {Detection} of {Outliers}},
	url = {https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm},
	urldate = {2024-01-22},
	file = {1.3.5.17. Detection of Outliers:C\:\\Users\\TJ\\Zotero\\storage\\6PCTMY99\\eda35h.html:text/html},
}

@article{paraschos_quantifying_2024,
	title = {Quantifying {Uncertainty} in {Segmentation} of {Computed} {Tomography}},
	url = {https://commons.erau.edu/db-srs/2023/poster-session-two/9},
	journal = {Student Research Symposium (SRS)},
	author = {Paraschos, Ioannis and Kienast, Ellie and Villar, Hadley Santos-Del and Reimer, Nathanial},
	month = jan,
	year = {2024},
	file = {Scholarly Commons - Student Research Symposium (SRS)\: Quantifying Uncertainty in Segmentation of Computed Tomography:C\:\\Users\\TJ\\Zotero\\storage\\JU2X7BWK\\9.html:text/html},
}

@article{mccormick_itk_2014,
	title = {{ITK}: enabling reproducible research and open science},
	volume = {8},
	issn = {1662-5196},
	shorttitle = {{ITK}},
	url = {https://www.frontiersin.org/articles/10.3389/fninf.2014.00013},
	abstract = {Reproducibility verification is essential to the practice of the scientific method. Researchers report their findings, which are strengthened as other independent groups in the scientific community share similar outcomes. In the many scientific fields where software has become a fundamental tool for capturing and analyzing data, this requirement of reproducibility implies that reliable and comprehensive software platforms and tools should be made available to the scientific community. The tools will empower them and the public to verify, through practice, the reproducibility of observations that are reported in the scientific literature. Medical image analysis is one of the fields in which the use of computational resources, both software and hardware, are an essential platform for performing experimental work. In this arena, the introduction of the Insight Toolkit (ITK) in 1999 has transformed the field and facilitates its progress by accelerating the rate at which algorithmic implementations are developed, tested, disseminated and improved. By building on the efficiency and quality of open source methodologies, ITK has provided the medical image community with an effective platform on which to build a daily workflow that incorporates the true scientific practices of reproducibility verification. This article describes the multiple tools, methodologies, and practices that the ITK community has adopted, refined, and followed during the past decade, in order to become one of the research communities with the most modern reproducibility verification infrastructure. For example, 207 contributors have created over 2400 unit tests that provide over 84\% code line test coverage. The Insight Journal, an open publication journal associated with the toolkit, has seen over 360,000 publication downloads. The median normalized closeness centrality, a measure of knowledge flow, resulting from the distributed peer code review system was high, 0.46.},
	urldate = {2024-01-24},
	journal = {Frontiers in Neuroinformatics},
	author = {McCormick, Matthew and Liu, Xiaoxiao and Ibanez, Luis and Jomier, Julien and Marion, Charles},
	year = {2014},
	file = {Full Text PDF:C\:\\Users\\TJ\\Zotero\\storage\\S5RPBDFR\\McCormick et al. - 2014 - ITK enabling reproducible research and open scien.pdf:application/pdf},
}

@article{hunter_matplotlib_2007,
	title = {Matplotlib: {A} {2D} graphics environment},
	volume = {9},
	doi = {10.1109/MCSE.2007.55},
	abstract = {Matplotlib is a 2D graphics package used for Python for application development, interactive scripting, and publication-quality image generation across user interfaces and operating systems.},
	number = {3},
	journal = {Computing in Science \& Engineering},
	author = {Hunter, J. D.},
	year = {2007},
	note = {Publisher: IEEE COMPUTER SOC},
	pages = {90--95},
}

@article{harris_array_2020,
	title = {Array programming with {NumPy}},
	volume = {585},
	url = {https://doi.org/10.1038/s41586-020-2649-2},
	doi = {10.1038/s41586-020-2649-2},
	number = {7825},
	journal = {Nature},
	author = {Harris, Charles R. and Millman, K. Jarrod and Walt, Stéfan J. van der and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and Kerkwijk, Marten H. van and Brett, Matthew and Haldane, Allan and Río, Jaime Fernández del and Wiebe, Mark and Peterson, Pearu and Gérard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
	month = sep,
	year = {2020},
	note = {Publisher: Springer Science and Business Media LLC},
	pages = {357--362},
}

@article{virtanen_scipy_2020,
	title = {{SciPy} 1.0: {Fundamental} {Algorithms} for {Scientific} {Computing} in {Python}},
	volume = {17},
	doi = {10.1038/s41592-019-0686-2},
	journal = {Nature Methods},
	author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and van der Walt, Stéfan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C J and Polat, İlhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Antônio H. and Pedregosa, Fabian and van Mulbregt, Paul and {SciPy 1.0 Contributors}},
	year = {2020},
	pages = {261--272},
}

@misc{noauthor_national_nodate,
	title = {A national lab is a different kind of research organization {\textbar} {PNNL}},
	url = {https://www.pnnl.gov/about},
	urldate = {2024-01-24},
	file = {A national lab is a different kind of research organization | PNNL:C\:\\Users\\TJ\\Zotero\\storage\\Y4U8KH8M\\about.html:text/html},
}

@misc{inc_matlab_2022,
	address = {Natick, Massachusetts, United States},
	title = {{MATLAB} version: 9.13.0 ({R2022b})},
	url = {https://www.mathworks.com},
	publisher = {The MathWorks Inc.},
	author = {Inc, The MathWorks},
	year = {2022},
}

@article{opencv_library,
    author = {Bradski, G.},
    citeulike-article-id = {2236121},
    journal = {Dr. Dobb's Journal of Software Tools},
    keywords = {bibtex-import},
    posted-at = {2008-01-15 19:21:54},
    priority = {4},
    title = {{The OpenCV Library}},
    year = {2000}
}

@misc{noauthor_opencv:_nodate,
	title = {{OpenCV}: {Hough} {Circle} {Transform}},
	url = {https://docs.opencv.org/3.4/da/d53/tutorial_py_houghcircles.html},
}